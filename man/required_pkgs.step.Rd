% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clean_levels.R, R/clean_names.R,
%   R/dummy_hash.R, R/lda.R, R/lemma.R, R/ngram.R, R/pos_filter.R,
%   R/sequence_onehot.R, R/stem.R, R/stopwords.R, R/text_normalization.R,
%   R/textfeature.R, R/texthash.R, R/tf.R, R/tfidf.R, R/tokenfilter.R,
%   R/tokenize.R, R/tokenize_bpe.R, R/tokenize_sentencepiece.R,
%   R/tokenize_wordpiece.R, R/tokenmerge.R, R/untokenize.R, R/word_embeddings.R
\name{required_pkgs.step_clean_levels}
\alias{required_pkgs.step_clean_levels}
\alias{required_pkgs.step_clean_names}
\alias{required_pkgs.step_dummy_hash}
\alias{required_pkgs.step_lda}
\alias{required_pkgs.step_lemma}
\alias{required_pkgs.step_ngram}
\alias{required_pkgs.step_pos_filter}
\alias{required_pkgs.step_sequence_onehot}
\alias{required_pkgs.step_stem}
\alias{required_pkgs.step_stopwords}
\alias{required_pkgs.step_text_normalization}
\alias{required_pkgs.step_textfeature}
\alias{required_pkgs.step_texthash}
\alias{required_pkgs.step_tf}
\alias{required_pkgs.step_tfidf}
\alias{required_pkgs.step_tokenfilter}
\alias{required_pkgs.step_tokenize}
\alias{required_pkgs.step_tokenize_bpe}
\alias{required_pkgs.step_tokenize_sentencepiece}
\alias{required_pkgs.step_tokenize_wordpiece}
\alias{required_pkgs.step_tokenmerge}
\alias{required_pkgs.step_untokenize}
\alias{required_pkgs.step_word_embeddings}
\title{S3 methods for tracking which additional packages are needed for steps.}
\usage{
\method{required_pkgs}{step_clean_levels}(x, ...)

\method{required_pkgs}{step_clean_names}(x, ...)

\method{required_pkgs}{step_dummy_hash}(x, ...)

\method{required_pkgs}{step_lda}(x, ...)

\method{required_pkgs}{step_lemma}(x, ...)

\method{required_pkgs}{step_ngram}(x, ...)

\method{required_pkgs}{step_pos_filter}(x, ...)

\method{required_pkgs}{step_sequence_onehot}(x, ...)

\method{required_pkgs}{step_stem}(x, ...)

\method{required_pkgs}{step_stopwords}(x, ...)

\method{required_pkgs}{step_text_normalization}(x, ...)

\method{required_pkgs}{step_textfeature}(x, ...)

\method{required_pkgs}{step_texthash}(x, ...)

\method{required_pkgs}{step_tf}(x, ...)

\method{required_pkgs}{step_tfidf}(x, ...)

\method{required_pkgs}{step_tokenfilter}(x, ...)

\method{required_pkgs}{step_tokenize}(x, ...)

\method{required_pkgs}{step_tokenize_bpe}(x, ...)

\method{required_pkgs}{step_tokenize_sentencepiece}(x, ...)

\method{required_pkgs}{step_tokenize_wordpiece}(x, ...)

\method{required_pkgs}{step_tokenmerge}(x, ...)

\method{required_pkgs}{step_untokenize}(x, ...)

\method{required_pkgs}{step_word_embeddings}(x, ...)
}
\arguments{
\item{x}{A recipe step}
}
\value{
A character vector
}
\description{
Recipe-adjacent packages always list themselves as a required package so that
the steps can function properly within parallel processing schemes.
}
\keyword{internal}
